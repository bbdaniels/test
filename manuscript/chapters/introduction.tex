
Welcome to Data for Development Impact.
This book is intended to serve as a resource guide
for people who collect or use primary data for development research.
In particular, the book is intended to guide the reader
through the process of research using primary survey data,
from survey design to fieldwork to data management to analysis.

This book will not teach you econometrics or epidemiology or agribusiness.
This book will not teach you how to design an impact evaluation.
This book will not teach you how to do data analysis, or how to code.
There are lots of really good resources out there for all of these things,
and they are much better than what we would be able to squeeze into this book.

What this book will teach you is how to think about data,
keeping in mind that you are not going to be the only person
collecting it, using it, or looking back on it.
We hope to provide you two key tools by the time you finish this book.
First, we want you to form a mental model of data collection as a ``social process'',
in which many people need to have the same idea about what is to be done, and when and where and by whom,
so that they can collaborate effectively on large, long-term projects.
Second, we want you to gain a sense of good practices for supporting these processes with Stata code.
As research teams and timespans have grown dramatically over the last decade,
it has no longer become efficient for everyone to have their own personal style
dictating how they use different functions, how they store data, and how they write code.

The team responsible for this book is known as DIME Analytics.\sidenote{\url{http://www.worldbank.org/en/research/dime/data-and-analytics}}
DIME Analytics works within the Development Impact Evaluation unit (DIME)\sidenote{\url{http://www.worldbank.org/en/research/dime}}
at the World Bank's Development Economics Research group (DEC).\sidenote{\url{http://www.worldbank.org/en/research/}}
DIME Analytics supports all of the research projects operated under the DIME umbrella,
and each of its members also works on their own development research and data science projects.
This book was conceived as a complement to the DIME Wiki,\sidenote{\url{http://dimewiki.worldbank.org/}}
which is a free online collection of resources and best practices.
DIME Analytics has built up these ideas, practices, and software tools
over the course of almost ten years of supporting hundreds of projects and staff in total.

In the time that we have been working in this field,
the proportion of projects that rely on primary empirical data has soared.\cite{angrist2017economic}
Today, the scope and scale of those projects continue to expand rapidly,
meaning that more and more people are working on the same data over longer and longer timeframes.
This is because, while administrative datasets and ``big data'' have important uses,
\textit{primary} data are critical for answering specific research questions.
As the ambition of development researchers grows, so too has the complexity of the data
that they rely on to make policy-relevant research conclusions from field experiments.
Unfortunately, this seems to have happened (so far) without the creation of
universal guidelines for practitioners to handle these data efficiently and transparently,
which would also provide quality markers beyond reputation for research consumers.

The main lesson we have learned working in the field over this time is that
the most important parts of primary data work are reproducibility and collaboration.
You will be working with people who have very different skillsets and mindsets than you,
from and in a variety of cultures and contexts, and you will have to adopt workflows
that everyone can agree upon, and that save time and hassle on every project.
This is not easy. But for some reason, the people who agreed to write this book enjoy doing it.
(In part this is because it has saved us ourselves a lot of time and effort.)
As we have worked with more and more DIME recruits -- economists, field managers, and research assistants --
we have realized that we barely have the time to give everyone the attention they deserve.
This book itself is therefore intended to be a labor-saving process for us:
we hope one day we can hand new people a copy of our accumulated knowledge in print,
and that it will do a better job teaching them than any one of us could alone.

This book complements the detailed-but-unstructured DIME Wiki
with a guided tour of the major tasks that make up primary data collection.
We will not give a lot of highly specific details in this text,
but we will point you to where they can be found, and give you a sense of what you need to find next.
Each chapter will focus on one task, and give a primarily narrative account of:

\begin{enumerate}
  \item What you will be doing
  \item Where in the workflow this task falls
  \item When it should be done
  \item Who you will be working with
  \item Why this task is important
  \item How to implement the most basic form of the task
\end{enumerate}

For the implementation portion, we will provide ``minimal'' code examples, like the following:

\marginnote[2\baselineskip]{This is a Stata code block.
Throughout this book, you will find examples like this,
which illustrate how to perform basic versions
of each task in Stata.}

\begin{Verbatim}[frame=lines,numbers=left,label=code.do]
// Load the auto dataset
sysuse auto.dta , clear

// Run a simple regression
reg price mpg rep78 headroom , coefl

// Transpose and store the output
matrix results = r(table)'

// Load the results into memory
clear
  svmat results , n(col)
\end{Verbatim}

We have tried really hard to make sure that all the Stata code runs,
and that each block should be well-formatted and use built-in functions.
If it does not, we will make sure to install the necessary user-written packages.
Providing some standardization to Stata code style is also a goal of this book,
since groups are collaborating on code in Stata more than ever before.

However, we will not explain Stata commands unless the behavior we are exploiting
is outside the usual expectation of its functionality;
we will comment the code generously (as you should),
but you should reference Stata help-files \texttt{h [command]}
whenever you do not understand the functionality that is being used.

We hope that these snippets will provide a strong foundation for your code style.
Alongside the collaborative view of data that we outlined above,
good code practices are a core part of the new data science of development research.
Code today is no longer a means to an end (such as a paper),
but it is part of the output itself: it is a means for communicating how something was done,
in a world where the credibility and transparency of data cleaning and analysis is increasingly important.

Just as data collection and management processes have become more social and collaborative,
code processes have as well. This means other people need to be able to read your code.
Not only are things like documentation and commenting important,
but code should be ``readable'' in the sense that others can:
(1) quickly understand what a portion of code is supposed to be doing;
(2) evaluate whether or not it does that thing correctly; and
(3) modify it efficiently either to test alternative hypotheses or to adapt into their own work.

To accomplish that, you should think of code in terms of three major elements: structure, syntax, and style.
The structure is the environment your code lives in:
good structure means that it is easy to find individual pieces of code that correspond to tasks.
Good structure also means that functional blocks are sufficiently independent from each other
that they can be shuffled around, repurposed, and even deleted without damaging other portions.
The syntax is the literal language of of your code.
Good syntax means that your code is readable in terms of how its mechanics implement ideas --
it should not require arcane reverse-engineering to figure out what a code chunk is trying to do.
Style, finally, is the way that the non-functional elements of your code convey their purpose.
Elements like spacing, indentation, and naming can make your code much more (or much less)
accessible to someone who is reading it for the first time and needs to understand it quickly and correctly.

Reproducible research follows naturally from high-quality data, process standardization, and good code.
High-quality data means that there will be substantially less noise
that is due to sampling, randomization, and cleaning error.
Process standardization means that there is little ambiguity about how something ought to be done,
and therefore the tools that are used to do it are set in advance.
Finally, good code enables easier pre-publication review,
as well as an easier replication process post-publication.


This is all to say -- while there is some upfront cost to learning to work the way we describe here,
you should start to save yourself and others a lot of time and hassle very quickly.
In part this is because you will learn how to do the essential things directly;
in part this is because you will find tools for the more advanced things;
and in part this is because you will have the mindset to doing everything else in a high-quality way.
We hope you will find this book helpful for accomplishing all of the above,
and that you will find that mastery of data helps you make an impact!

- The DIME Analytics Team

\mainmatter
